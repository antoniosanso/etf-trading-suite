name: Trading Suite ‚Äî Unified (Full Fetch ‚Üí Index ‚Üí Model ‚Üí Persist)

on:
  workflow_dispatch:
  schedule:
    - cron: "45 15 * * 1-5"

permissions:
  contents: write

jobs:
  unified:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout suite
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install runtime deps
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy yfinance pandas-datareader pyyaml

      - name: üîÑ Sync ETF Universe
        run: |
          echo "Fetching latest ETF universe..."
          curl -L -o etf-trading-config/universe.csv \
          https://raw.githubusercontent.com/antoniosanso/etf-trading-suite/main/etf-trading-config/universe.csv
          head -n 5 etf-trading-config/universe.csv

      - name: üåç Fetch EOD data from Yahoo Finance
        run: |
          echo "Downloading full historical data for all ETF in universe..."
          mkdir -p data latest
          python - <<'EOF'
          import pandas as pd, yfinance as yf, os
          u = pd.read_csv("etf-trading-config/universe.csv")
          tickers = u["ticker_bi"].dropna().unique().tolist()
          os.makedirs("data", exist_ok=True)
          count = 0
          for t in tickers:
              try:
                  d = yf.download(t, period="5y", interval="1d", progress=False)
                  if len(d) > 0:
                      d.to_csv(f"data/{t}.csv")
                      count += 1
              except Exception as e:
                  print(f"‚ö†Ô∏è {t}: {e}")
          print(f"‚úÖ Downloaded {count} ETF files.")
          EOF

          echo "Compiling latest snapshot..."
          python - <<'EOF'
          import pandas as pd, glob
          files = glob.glob("data/*.csv")
          dfs = []
          for f in files:
              df = pd.read_csv(f)
              df["Ticker"] = os.path.basename(f).replace(".csv","")
              dfs.append(df.tail(1))
          pd.concat(dfs).to_csv("latest/eod-latest.csv", index=False)
          print(f"‚úÖ Snapshot saved to latest/eod-latest.csv with {len(dfs)} ETFs.")
          EOF

      - name: Prepare EOD for model (fix dtypes)
        run: |
          python scripts/fix_eod_types.py \
            --snapshot latest/eod-latest.csv \
            --output   etf-trading-engine/data/eod.csv

      - name: Run model
        env:
          PYTHONPATH: ${{ github.workspace }}:${{ github.workspace }}/src:${{ github.workspace }}/etf-trading-engine:${{ github.workspace }}/etf-trading-engine/src
        run: |
          mkdir -p outputs
          python etf-trading-engine/scripts/run_ci_backtest.py \
            --config ./etf-trading-config/model.yaml \
            --data   ./etf-trading-engine/data/eod.csv \
            --outdir ./outputs

      - name: System checks (auto QA)
        run: |
          python scripts/system_checks.py \
            --index latest/index.json \
            --eod latest/eod-latest.csv \
            --report outputs

      - name: Persist full dataset to repository
        run: |
          echo "üì¶ Persisting updated dataset..."
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/*.csv latest/*.csv || true
          git diff --cached --quiet || git commit -m "Auto-update: full EOD dataset refreshed"
          git push origin main || echo "‚ö†Ô∏è Nothing new to push (already up-to-date)"
